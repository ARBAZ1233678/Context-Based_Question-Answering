{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyN/dOhYB6SWwStp1xbjftHv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ARBAZ1233678/Context-Based_Question-Answering/blob/main/Question_Answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load SQuAD 2.0 dataset from drive"
      ],
      "metadata": {
        "id": "ewBVqQvIHPen"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm2iXEDAHBWa",
        "outputId": "d3b05915-02ae-4e51-a43c-88ff0d1da9cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot stat '/content/drive/My Drive/utils_squad.py': No such file or directory\n",
            "cp: cannot stat '/content/drive/My Drive/utils_squad_evaluate.py': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "import io\n",
        "import os\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "\n",
        "sys.path.append('/content/drive/My Drive/')\n",
        "\n",
        "!cp -r \"/content/drive/MyDrive/Task 3/train-v2.0.json\" '/content/'\n",
        "!cp -r \"/content/drive/MyDrive/Task 3/dev-v2.0.json\" '/content/'\n",
        "!cp -r \"/content/drive/My Drive/utils_squad.py\" '/content/'\n",
        "!cp -r \"/content/drive/My Drive/utils_squad_evaluate.py\" '/content/'\n",
        "\n",
        "train_file = '/content/drive/MyDrive/Task 3/train-v2.0.json'\n",
        "validation_file = '/content/drive/MyDrive/Task 3/dev-v2.0.json'\n",
        "\n",
        "with open(train_file) as f:\n",
        "    raw_train_data = json.load(f)\n",
        "with open(validation_file) as f:\n",
        "    raw_val_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers import BertForQuestionAnswering\n",
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "slow_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "save_path = \"bert_base_uncased/\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "slow_tokenizer.save_pretrained(save_path)\n",
        "\n",
        "# Load the fast tokenizer from saved file\n",
        "tokenizer = BertWordPieceTokenizer(\"bert_base_uncased/vocab.txt\", lowercase=True)\n",
        "max_len = 384"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuMksJn7Hr1J",
        "outputId": "bed9be08-f01d-4262-ca79-56e2f2f8539d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a class to save the data form sQuAD"
      ],
      "metadata": {
        "id": "oqO_nujKH_L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SquadSample:\n",
        "\n",
        "    def __init__(self, context, question, basic_answer, more_answers, start_idx):\n",
        "        self.context = context\n",
        "        self.question = question\n",
        "        self.basic_answer = basic_answer\n",
        "        self.more_answers = more_answers\n",
        "        self.start_idx = start_idx\n",
        "        self.end_idx = None\n",
        "        self.start_idx_token = start_idx\n",
        "        self.end_idx_token = None\n",
        "        self.offsets = None\n",
        "        self.input_ids = None\n",
        "        self.attention_mask = None\n",
        "        self.token_type_ids = None\n",
        "        self.validExample = True\n",
        "\n",
        "    def preprocess(self): # function to preprocess data\n",
        "       # Clean context, answer and question\n",
        "        self.context = \" \".join(str(self.context).split())\n",
        "        self.question = \" \".join(str(self.question).split())\n",
        "\n",
        "        contextTokenizer =  tokenizer.encode(self.context)\n",
        "\n",
        "        if self.basic_answer is not None: # in case we have an answer\n",
        "\n",
        "          self.basic_answer = \" \".join(str(self.basic_answer).split())\n",
        "          #Calculate end_idx\n",
        "          self.end_idx = self.start_idx + len(self.basic_answer)\n",
        "          if (self.end_idx >=len(self.context)):\n",
        "              self.validExample= False\n",
        "              return\n",
        "\n",
        "          #find characters of context that are part of answer\n",
        "          is_part_of_answer = [0]*len(self.context)\n",
        "          for i in range (self.start_idx, self.end_idx):\n",
        "              is_part_of_answer[i] = 1\n",
        "\n",
        "\n",
        "          #find index of token that corresponds to start and the end of the answer\n",
        "          answer_id_token=[]\n",
        "          for idx, (start,end) in enumerate(contextTokenizer.offsets):\n",
        "              if (sum(is_part_of_answer[start:end]) >0 ):\n",
        "                  answer_id_token.append(idx)\n",
        "          #data to predict\n",
        "          if len(answer_id_token) == 0 :\n",
        "              self.validExample=False\n",
        "              return\n",
        "          self.start_idx_token = answer_id_token[0]\n",
        "          self.end_idx_token = answer_id_token[-1]\n",
        "        self.offsets = contextTokenizer.offsets\n",
        "\n",
        "        # work on question\n",
        "        questionTokinizer  = tokenizer.encode(self.question)\n",
        "\n",
        "        #Create model's inputs\n",
        "        self.input_ids = contextTokenizer.ids + questionTokinizer.ids[1:]\n",
        "        self.attention_mask = [1] * len (self.input_ids)\n",
        "        self.token_type_ids = [0] * len(contextTokenizer.ids) + [1]*len(questionTokinizer.ids[1:])\n",
        "\n",
        "        # fix padding\n",
        "        padding_length = max_len - len(self.input_ids)\n",
        "        if padding_length > 0:\n",
        "            self.input_ids = self.input_ids + ([0] * padding_length)\n",
        "            self.attention_mask = self.attention_mask + ([0] * padding_length)\n",
        "            self.token_type_ids = self.token_type_ids + ([0] * padding_length)\n",
        "        elif padding_length < 0:\n",
        "            self.validExample= False\n",
        "            return"
      ],
      "metadata": {
        "id": "f-L274OsH__2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function that helps save data from json files"
      ],
      "metadata": {
        "id": "ADOGcZ0BIHSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_squad_examples(raw_data):\n",
        "    squad_examples = []\n",
        "    for item in raw_data[\"data\"]:\n",
        "        for para in item[\"paragraphs\"]:\n",
        "            context = para[\"context\"]\n",
        "            for qa in para[\"qas\"]:\n",
        "                question = qa[\"question\"]\n",
        "                if qa[\"answers\"]:\n",
        "                  answer_text = qa[\"answers\"][0][\"text\"]\n",
        "                  all_answers = [_[\"text\"] for _ in qa[\"answers\"]]\n",
        "                  start_char_idx = qa[\"answers\"][0][\"answer_start\"]\n",
        "                  #context, question, basic_answer, more_answers, start_idx\n",
        "                  squad_eg = SquadSample(context,question, answer_text, all_answers, start_char_idx)\n",
        "                else:\n",
        "                  squad_eg = SquadSample(context,question, None, None, None) #context, question\n",
        "                squad_eg.preprocess()\n",
        "                squad_examples.append(squad_eg)\n",
        "    return squad_examples"
      ],
      "metadata": {
        "id": "cvrruhMXIIIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function that create ttwo dictionaries, one for the input and one for the target"
      ],
      "metadata": {
        "id": "cQE-tyJOIZ7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_inputs_targets(squad_examples):\n",
        "    dataset_dict = {\n",
        "        \"input_ids\" : [],\n",
        "        \"attention_mask\" : [],\n",
        "        \"token_type_ids\" : [],\n",
        "        \"start_idx_token\" : [],\n",
        "        \"end_idx_token\" : []\n",
        "    }\n",
        "    for item in squad_examples:\n",
        "        if item.validExample is True:\n",
        "            for key in dataset_dict:\n",
        "                dataset_dict[key].append(getattr(item, key))\n",
        "    for key in dataset_dict:\n",
        "        dataset_dict[key] = np.array(dataset_dict[key],dtype=np.float16)\n",
        "    x = [dataset_dict[\"input_ids\"], dataset_dict[\"attention_mask\"], dataset_dict[\"token_type_ids\"]]\n",
        "    y = [dataset_dict[\"start_idx_token\"], dataset_dict[\"end_idx_token\"]]\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "t8ZIbaKdIbCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = create_squad_examples(raw_train_data)  # save the data for the training set\n",
        "\n",
        "val_data = create_squad_examples(raw_val_data)  # save the data for the validation set"
      ],
      "metadata": {
        "id": "dX8pMdMmIjmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.DataFrame.from_records([vars(line) for line in data])\n",
        "train_data[[\"context\",\"question\",\"basic_answer\"]].head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "EAVOixqHJXNc",
        "outputId": "5e8a1bd0-9f86-424a-ed55-3d76c433912b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...   \n",
              "\n",
              "                                            question         basic_answer  \n",
              "0           When did Beyonce start becoming popular?    in the late 1990s  \n",
              "1  What areas did Beyonce compete in when she was...  singing and dancing  \n",
              "2  When did Beyonce leave Destiny's Child and bec...                 2003  \n",
              "3        In what city and state did Beyonce grow up?       Houston, Texas  \n",
              "4         In which decade did Beyonce become famous?           late 1990s  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c1e77ab-a180-4464-9d6b-823da2dcaa9f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>question</th>\n",
              "      <th>basic_answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce start becoming popular?</td>\n",
              "      <td>in the late 1990s</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>What areas did Beyonce compete in when she was...</td>\n",
              "      <td>singing and dancing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
              "      <td>2003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In what city and state did Beyonce grow up?</td>\n",
              "      <td>Houston, Texas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
              "      <td>In which decade did Beyonce become famous?</td>\n",
              "      <td>late 1990s</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c1e77ab-a180-4464-9d6b-823da2dcaa9f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c1e77ab-a180-4464-9d6b-823da2dcaa9f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c1e77ab-a180-4464-9d6b-823da2dcaa9f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-763a723c-ccb7-4bbb-944e-6c41ac1b2d96\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-763a723c-ccb7-4bbb-944e-6c41ac1b2d96')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-763a723c-ccb7-4bbb-944e-6c41ac1b2d96 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_data[[\\\"context\\\",\\\"question\\\",\\\"basic_answer\\\"]]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Beyonc\\u00e9 Giselle Knowles-Carter (/bi\\u02d0\\u02c8j\\u0252nse\\u026a/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny's Child. Managed by her father, Mathew Knowles, the group became one of the world's best-selling girl groups of all time. Their hiatus saw the release of Beyonc\\u00e9's debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \\\"Crazy in Love\\\" and \\\"Baby Boy\\\".\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"What areas did Beyonce compete in when she was growing up?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"basic_answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"singing and dancing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, y_train = create_inputs_targets(data)  # split the training data to input and target\n",
        "\n",
        "x_eval, y_eval = create_inputs_targets(val_data)  # split the validation data to input and target"
      ],
      "metadata": {
        "id": "pSRLloOsJoD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_stride = 64\n",
        "max_seq_length = 128\n",
        "max_query_length = 32\n",
        "batch_size = 16\n"
      ],
      "metadata": {
        "id": "ivSF5PNjJxZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Datasets"
      ],
      "metadata": {
        "id": "SaBNRBGsLF__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# Convert to Tensors and build dataset\n",
        "train_data = TensorDataset(torch.tensor(x_train[0], dtype=torch.int64),\n",
        "                           torch.tensor(x_train[1], dtype=torch.float),\n",
        "                           torch.tensor(x_train[2], dtype=torch.int64),\n",
        "                           torch.tensor(y_train[0], dtype=torch.int64),\n",
        "                           torch.tensor(y_train[1], dtype=torch.int64))\n",
        "\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "HxW3u9kOLKEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to Tensors and build dataset\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_data_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "eval_data = TensorDataset(torch.tensor(x_eval[0], dtype=torch.int64),\n",
        "                          torch.tensor(x_eval[1], dtype=torch.float),\n",
        "                          torch.tensor(x_eval[2], dtype=torch.int64),\n",
        "                          torch.tensor(y_eval[0], dtype=torch.int64),\n",
        "                          torch.tensor(y_eval[1], dtype=torch.int64))\n",
        "\n",
        "eval_sampler = SequentialSampler(eval_data)\n",
        "validation_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "Xyv34YsRLMUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check for GPU availability"
      ],
      "metadata": {
        "id": "pY5QEeKHLPfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# First checking if GPU is available\n",
        "train_on_gpu=torch.cuda.is_available()\n",
        "\n",
        "if(train_on_gpu):\n",
        "    print('Training on GPU.')\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print('No GPU available, training on CPU.')\n",
        "    device = 'cpu'\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhZqrSulLROo",
        "outputId": "f0a4d102-dba0-4b5e-8018-89a2a5d8b7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, training on CPU.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize model"
      ],
      "metadata": {
        "id": "fQJhrQsKM0nj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForQuestionAnswering.from_pretrained('bert-base-uncased').to(device=device)\n",
        "param_optimizer = list(model.named_parameters())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQQ_xBFWM24c",
        "outputId": "a29dea6a-1760-4653-ca0b-c8be97155d21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.Adam(lr=1e-5, betas=(0.9, 0.98), eps=1e-9, params=optimizer_grouped_parameters)\n"
      ],
      "metadata": {
        "id": "Hip20AzTM8WT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "htJ4AkLuM-Xa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "2UF08quQNAo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function for text normalization"
      ],
      "metadata": {
        "id": "dRzcCtfhNJDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text"
      ],
      "metadata": {
        "id": "xbWnWH1dNIXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = \"\".join(ch for ch in text if ch not in set(string.punctuation))\n",
        "    regex = re.compile(r\"\\b(a|an|the)\\b\", re.UNICODE)\n",
        "    text = re.sub(regex, \" \", text)\n",
        "    text = \" \".join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    # ============================================ TRAINING ============================================================\n",
        "    print(\"Training epoch \", str(epoch))\n",
        "\n",
        "    model.train()\n",
        "    tr_loss = 0\n",
        "    nb_tr_steps = 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        inputs = {'input_ids':       batch[0],\n",
        "                  'attention_mask':  batch[1],\n",
        "                  'token_type_ids':  batch[2],\n",
        "                  'start_positions': batch[3],\n",
        "                  'end_positions':   batch[4]}\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    print(f\"\\nTraining loss={tr_loss / nb_tr_steps:.4f}\")\n",
        "\n",
        "    # ============================================ VALIDATION ==========================================================\n",
        "    model.eval()\n",
        "    currect_query = 0\n",
        "    correct_ans = 0\n",
        "    valid_examples = [x for x in val_data if x.validExample is True]\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, start_positions, end_positions = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "          start_logits, end_logits =  model(input_ids=input_ids,\n",
        "                                              attention_mask=attention_mask,\n",
        "                                              token_type_ids=token_type_ids, return_dict=False)\n",
        "\n",
        "          pred_start, pred_end = start_logits.detach().cpu().numpy(), end_logits.detach().cpu().numpy()\n",
        "\n",
        "        for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "            squad_eg = valid_examples[currect_query]\n",
        "            currect_query += 1\n",
        "            offsets = squad_eg.offsets\n",
        "            start = np.argmax(start)\n",
        "            end = np.argmax(end)\n",
        "            if start >= len(offsets):\n",
        "                continue\n",
        "            pred_char_start = offsets[start][0]\n",
        "            if end < len(offsets):\n",
        "                pred_char_end = offsets[end][1]\n",
        "                pred_ans = squad_eg.context[pred_char_start:pred_char_end]\n",
        "            else:\n",
        "                pred_ans = squad_eg.context[pred_char_start:]\n",
        "            normalized_pred_ans = normalize_text(pred_ans)\n",
        "            normalized_true_ans = [normalize_text(x) for x in squad_eg.more_answers]\n",
        "            if normalized_pred_ans in normalized_true_ans:\n",
        "                correct_ans += 1\n",
        "    acc = correct_ans / len(y_eval[0])\n",
        "\n",
        "    print(f\"\\nAccuracy score={acc:.2f}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnOP9Nt_NR7W",
        "outputId": "5a4482e3-ffec-4b82-88b8-55cff2b07c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training epoch  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "TKBPyEap_mMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\"data\":\n",
        "    [\n",
        "        {\"title\": \"Tesla's Biography\",\n",
        "         \"paragraphs\": [\n",
        "             {\n",
        "                 \"context\": \"Nikola Tesla was a Serbian-American inventor, electrical engineer, mechanical engineer, \"\n",
        "                            \"and futurist best known for his contributions to the design of the modern alternating \"\n",
        "                            \"current (AC) electricity supply system. Born and raised in the Austrian Empire,Tesla \"\n",
        "                            \"studied engineering and physics in the 1870s without receiving a degree. In 1884, he \"\n",
        "                            \"moved to United States. In 1887, Tesla developed an induction motor that ran on alternating \"\n",
        "                            \"current (AC), a power system format that was rapidly expanding in Europe and the United \"\n",
        "                            \"States because of its advantages in long-distance, high-voltage transmission. Tesla became \"\n",
        "                            \"a vegetarian in his later years, living on only milk, bread, honey, and vegetable juices. \"\n",
        "                            \"On 7 January 1943, at the age of 86, Tesla died alone in Room 3327 of the Hotel New Yorker. \"\n",
        "                            \"Tesla wrote a number of books and articles for magazines and journals. Among his books are \"\n",
        "                            \"My Inventions: The Autobiography of Nikola Tesla, compiled and edited by Ben Johnston \"\n",
        "                            \"in 1983 from a series of 1919 magazine articles by Tesla which were republished in 1977. \"\n",
        "                            \"Tesla's legacy has endured in books, films, radio, TV, music, live theater, comics, and \"\n",
        "                            \"video games. The impact of the technologies invented or envisioned by Tesla is a recurring \"\n",
        "                            \"theme in several types of science fiction. \",\n",
        "                 \"qas\": [\n",
        "                     {\"question\": \"When did Tesla becοme a vegetarian?\",\n",
        "                      \"id\": \"Q1\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"When did Tesla move to United States ?\",\n",
        "                      \"id\": \"Q2\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"What year did Tesla die?\",\n",
        "                      \"id\": \"Q3\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"Who edited the book My Inventions: The Autobiography of Nikola Tesla?\",\n",
        "                      \"id\": \"Q4\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"In what age did Tesla died?\",\n",
        "                      \"id\": \"Q5\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"Who developed an induction motor?\",\n",
        "                      \"id\": \"Q6\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"Where Tesla was born?\",\n",
        "                      \"id\": \"Q7\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                     {\"question\": \"What did Tesla study?\",\n",
        "                      \"id\": \"Q8\",\n",
        "                      \"answers\":\"\"\n",
        "                      },\n",
        "                 ]}]}]}\n",
        "\n",
        "model.eval()\n",
        "test_samples = create_squad_examples(data)\n",
        "x_test, _ = create_inputs_targets(test_samples)\n",
        "pred_start, pred_end = model(torch.tensor(x_test[0], dtype=torch.int64, device=device),\n",
        "                             torch.tensor(x_test[1], dtype=torch.float, device=device),\n",
        "                             torch.tensor(x_test[2], dtype=torch.int64, device=device), return_dict=False)\n",
        "pred_start, pred_end = pred_start.detach().cpu().numpy(), pred_end.detach().cpu().numpy()\n",
        "for idx, (start, end) in enumerate(zip(pred_start, pred_end)):\n",
        "    test_sample = test_samples[idx]\n",
        "    offsets = test_sample.offsets\n",
        "    start = np.argmax(start)\n",
        "    end = np.argmax(end)\n",
        "    pred_ans = None\n",
        "    if start >= len(offsets):\n",
        "        continue\n",
        "    pred_char_start = offsets[start][0]\n",
        "    if end < len(offsets):\n",
        "        pred_ans = test_sample.context[pred_char_start:offsets[end][1]]\n",
        "    else:\n",
        "        pred_ans = test_sample.context[pred_char_start:]\n",
        "    print(\"Q: \" + test_sample.question)\n",
        "    print(\"A: \" + pred_ans)\n",
        "    print(\"----------------------------------------\\n\")"
      ],
      "metadata": {
        "id": "CU63hvSM_aat"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}